{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aZ59XN1zK8Uo",
   "metadata": {
    "id": "aZ59XN1zK8Uo"
   },
   "source": [
    "## Setup googlecolab env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iJ7v7OaLLlEH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJ7v7OaLLlEH",
    "outputId": "f7283b40-f9db-47ee-9446-461b91b7e55a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U3uiYFTYMhYx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3uiYFTYMhYx",
    "outputId": "3d872a91-45b0-4744-eba8-9dc171ccb19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/92/6153f4912b84ee1ab53ab45663d23e7cf3704161cb5ef18b0c07e207cef2/transformers-4.7.0-py3-none-any.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 7.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 52.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 51.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.7.0\n",
      "Requirement already satisfied: fastai in /usr/local/lib/python3.7/dist-packages (1.0.61)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai) (0.10.0+cu102)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.352.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.9.0+cu102)\n",
      "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.19.5)\n",
      "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai) (2.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.8.2)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (57.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.4.1)\n",
      "Collecting discreteMarkovChain\n",
      "  Downloading https://files.pythonhosted.org/packages/77/85/d1d2e71296f9cd4f5d8d1e2c198dcb44bbc056722351ca24e70b3c45b090/discreteMarkovChain-0.22-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from discreteMarkovChain) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from discreteMarkovChain) (1.4.1)\n",
      "Installing collected packages: discreteMarkovChain\n",
      "Successfully installed discreteMarkovChain-0.22\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install fastai\n",
    "! pip install discreteMarkovChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IqoanpDdPKA9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqoanpDdPKA9",
    "outputId": "bd47114a-2768-4e1f-b698-58a45b2051c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 22 09:43:52 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   51C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1da4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For google colab\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "script_dir =\"/content/drive/MyDrive/Snippet Generation Projects 14.06.2021/ExtractiveSnipp\"\n",
    "sys.path.insert(0, script_dir)\n",
    "data_snippets = json.load(open(os.path.join(script_dir, \"data/snippets.txt\")), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98c72c44",
   "metadata": {
    "id": "98c72c44"
   },
   "outputs": [],
   "source": [
    "# for running from pc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "script_dir = os.path.dirname(Path())\n",
    "data_snippets = json.load(open(os.path.join(script_dir, \"data/snippets.txt\")), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4130749",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "fabfbb94efd0487d9d4007731efb651b",
      "c3409288f983432387160b54cb16704b",
      "497a33d67fd24cbbb10550b8f177a3c0",
      "f5d207e85f5640e3858419a38837290e",
      "de5844b309444039a75610c992b269d1",
      "77f6327fcfae4340ba47a992e812cc4d",
      "7296c218ab304f95beba77671030f7cb",
      "2573a61c0701450cae8ccbf220213579",
      "136b2c7dc3a244ccb24ed6ba7d6cf4a1",
      "6499773ba805468d9234d486fce0ffd3",
      "6acf8444c00d43418f82fde5131d65aa",
      "15aea6429edb418882bb4136583b0797",
      "7c747c98d8ed4f7991e251fc4404ea2d",
      "758f91563cc24542a3bb7c241371ce6c",
      "ce53a2453da545ca98590447a3bea7e7",
      "76144edcf1a644fc85705f5f3277e98e",
      "ce1f0490532048969a17b5cab3018667",
      "68c53fac07764e6e8ddeb0c3a5522c9d",
      "6db8725d6073448e92728fb7ec4b7e51",
      "e78d243062524f709d5cfce00e705445",
      "75335056443147d2bfa3c6840fe1183f",
      "c33f6f28355146f09a3c0ff5c2edbc22",
      "300a9ad1919745e0bb064c0a24872578",
      "6ba2714e8a4b4926a29745879d9202f3",
      "0711fe0e17f44a809ad502f1bea622f5",
      "1bb1824d78c040989241849b6bf0e6dc",
      "e00ca8181b444ff98be59df480be85b8",
      "dd24551affda44498b056d42d390516a",
      "51112895f0984853aa72e2c7d7166b8c",
      "427f5fae2c01431184e49170cb5fbb0c",
      "7a455b71258c40f5abd5894020dfe3d8",
      "54431eb739304492b034bc55fe0303d0",
      "e88a24f225bc4ccba56a9dbcabb43bde",
      "201d97219c2f41f3bacfc87560fdda1b",
      "cfa62bd3b00f4da7a27810819d104337",
      "3634ec9092dc4f9c91fc73557deebb1f",
      "e5331efd11054c73acc73df6c8e9a10d",
      "6862247d45ae41148eab375db99d60ec",
      "4bf04b7b31ff450484d27032fd54d9aa",
      "b237af0ac868461aa7b14783f0d666e5",
      "be7396737a8b4cdbacd83ffd75b4e277",
      "90e85715d07d480c9d327b722fe440b4",
      "0a338f9975964fa5b8c6108b78aa6b30",
      "276b2f3c8efa49bc8c99911db544b858",
      "c6d8f96dc9aa45368834255fc69244f5",
      "c4f2272ab4c949188522c549bac43fbe",
      "53395e59bd55413f9729192aeb20211f",
      "a694f1aba2b24f01a5d3cdd2c1c6fda2"
     ]
    },
    "id": "f4130749",
    "outputId": "e07ea356-7838-430b-960e-7b0fb7f45028"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C5673E2558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C5673E2558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03133  -0.063386 -0.016075 -0.010349 ...  0.064889 -0.032428 -0.045757  0.053705]\n",
      " [ 0.050809 -0.016524  0.015738 -0.042864 ... -0.01628   0.009767  0.031701  0.017881]\n",
      " [ 0.053329 -0.017461  0.053533  0.057924 ... -0.007853 -0.022668 -0.040348 -0.035826]], shape=(3, 512), dtype=float32)\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"chkla/roberta-argument\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NON-ARGUMENT\",\n",
      "    \"1\": \"ARGUMENT\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"ARGUMENT\": 1,\n",
      "    \"NON-ARGUMENT\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.6.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNLearner(data=TextClasDataBunch;\n",
      "\n",
      "Train: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: ..\\pretrained_models2;\n",
      "\n",
      "Valid: LabelList (0 items)\n",
      "x: TextList\n",
      "\n",
      "y: CategoryList\n",
      "\n",
      "Path: ..\\pretrained_models2;\n",
      "\n",
      "Test: None, model=SequentialRNN(\n",
      "  (0): MultiBatchEncoder(\n",
      "    (module): AWD_LSTM(\n",
      "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
      "      (encoder_dp): EmbeddingDropout(\n",
      "        (emb): Embedding(60000, 400, padding_idx=1)\n",
      "      )\n",
      "      (rnns): ModuleList(\n",
      "        (0): WeightDropout(\n",
      "          (module): LSTM(400, 1152, batch_first=True)\n",
      "        )\n",
      "        (1): WeightDropout(\n",
      "          (module): LSTM(1152, 1152, batch_first=True)\n",
      "        )\n",
      "        (2): WeightDropout(\n",
      "          (module): LSTM(1152, 400, batch_first=True)\n",
      "        )\n",
      "      )\n",
      "      (input_dp): RNNDropout()\n",
      "      (hidden_dps): ModuleList(\n",
      "        (0): RNNDropout()\n",
      "        (1): RNNDropout()\n",
      "        (2): RNNDropout()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): PoolingLinearClassifier(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x000001C50CF93828>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=WindowsPath('../pretrained_models2'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
      "learn: ...\n",
      "alpha: 2.0\n",
      "beta: 1.0], layer_groups=[Sequential(\n",
      "  (0): Embedding(60000, 400, padding_idx=1)\n",
      "  (1): Embedding(60000, 400, padding_idx=1)\n",
      "  (2): LSTM(400, 1152, batch_first=True)\n",
      "  (3): LSTM(1152, 1152, batch_first=True)\n",
      "  (4): LSTM(1152, 400, batch_first=True)\n",
      "  (5): RNNDropout()\n",
      "  (6): RNNDropout()\n",
      "  (7): RNNDropout()\n",
      "  (8): RNNDropout()\n",
      "  (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): Dropout(p=0.27999999999999997, inplace=False)\n",
      "  (11): Linear(in_features=1200, out_features=50, bias=True)\n",
      "  (12): ReLU(inplace=True)\n",
      "  (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (14): Dropout(p=0.1, inplace=False)\n",
      "  (15): Linear(in_features=50, out_features=2, bias=True)\n",
      ")], add_time=True, silent=False)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import tensorflow_hub as hub\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from fastai.text.learner import load_learner\n",
    "\n",
    "nltk.download('punkt')\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embeddings = embed([\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\", \"Agree?\"])\n",
    "\n",
    "print(embeddings)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"chkla/roberta-argument\")\n",
    "arg_model = AutoModelForSequenceClassification.from_pretrained(\"chkla/roberta-argument\")\n",
    "print(arg_model.config)\n",
    "\n",
    "model_path = \"../pretrained_models2\"\n",
    "# model_path =\"/content/drive/MyDrive/Snippet Generation Projects 14.06.2021/pretrained_models2\"\n",
    "claim_classifier = load_learner(model_path)\n",
    "print(claim_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38a84898",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38a84898",
    "outputId": "d8735697-3b19-456a-a4d6-07b27850c781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "for idx, arguments in enumerate(data_snippets):\n",
    "    arguments['index'] = idx\n",
    "    # print(arguments)\n",
    "\n",
    "# removing arguments with sentences less then 3\n",
    "print(len(data_snippets))\n",
    "count = 0\n",
    "data_snippets_filtered = []\n",
    "for argument_x in data_snippets:\n",
    "\n",
    "    if len(argument_x['sentences']) >= 3:\n",
    "        data_snippets_filtered.append(argument_x)\n",
    "        count = count + 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48bf5443",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48bf5443",
    "outputId": "02f32b8c-afca-4bd3-f746-946ce7e71e8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['abortion', 'brexit', 'climate change', 'death_penalty', 'donald trump', 'feminism', 'google', 'nuclear_energy', 'trump', 'vegan']\n",
      "{'abortion': 10, 'brexit': 9, 'climate change': 6, 'death_penalty': 9, 'donald trump': 10, 'feminism': 9, 'google': 8, 'nuclear_energy': 3, 'trump': 5, 'vegan': 8}\n"
     ]
    }
   ],
   "source": [
    "argument_query_list =[]\n",
    "for arguments in data_snippets_filtered:\n",
    "    if arguments['query'] not in argument_query_list:\n",
    "        argument_query_list.append(arguments['query'])\n",
    "\n",
    "print(len(argument_query_list))\n",
    "print(argument_query_list)\n",
    "arguments_query_count =  {}\n",
    "for query in argument_query_list:\n",
    "    \n",
    "    arguments_count = 0\n",
    "    for argument in data_snippets_filtered: \n",
    "        if argument['query']== query:\n",
    "            arguments_count = arguments_count +1\n",
    "        \n",
    "        arguments_query_count[query]= arguments_count\n",
    "    \n",
    "argument_count_list=arguments_query_count\n",
    "print(argument_count_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "GUHxAygp9or7",
   "metadata": {
    "id": "GUHxAygp9or7"
   },
   "outputs": [],
   "source": [
    "# Spliting Arguments topic-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83d612eb",
   "metadata": {
    "id": "83d612eb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "940f57c1",
   "metadata": {
    "id": "940f57c1"
   },
   "outputs": [],
   "source": [
    "dev_args_set = ['feminism','death_penalty', 'brexit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4e97b39",
   "metadata": {
    "id": "f4e97b39"
   },
   "outputs": [],
   "source": [
    "test_args =[]\n",
    "dev_args  =[]\n",
    "for args in data_snippets_filtered:\n",
    "    if args['query'] in dev_args_set:\n",
    "        dev_args.append(args)\n",
    "    else:\n",
    "        test_args.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df03e45a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df03e45a",
    "outputId": "ff3a3cfb-1391-4e5b-90a3-87fc71abaa9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0928328b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0928328b",
    "outputId": "661be74a-7916-496f-d104-307a2f8c6384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0127df7",
   "metadata": {
    "id": "a0127df7"
   },
   "outputs": [],
   "source": [
    "# setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0OOhpEh5gd1P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OOhpEh5gd1P",
    "outputId": "259e1d0b-c6c1-4bf9-e3cb-a7205ac20e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "720195f1",
   "metadata": {
    "id": "720195f1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from snippetGenerator import SnippetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "791b6e8e",
   "metadata": {
    "id": "791b6e8e"
   },
   "outputs": [],
   "source": [
    "def evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method):\n",
    "    snippetGenerator= SnippetGenerator(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "                                     argument_context, argumentative_score_method)\n",
    "    snippets = snippetGenerator.get_snippets(arguments)\n",
    "    count, accuracy= snippetGenerator.get_accuracy(arguments, snippets)\n",
    "    return count,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266b8e5",
   "metadata": {
    "id": "9266b8e5"
   },
   "source": [
    "# Test Snippet Generation using different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5410dc",
   "metadata": {
    "id": "cb5410dc"
   },
   "source": [
    "## 1. Previous Vesion of the snippet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bfc8d7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "4bfc8d7b",
    "outputId": "b864277b-d493-4181-ae98-9726db94adcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [0, 1, 0]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 0\n",
      "snippets generated File created \n",
      "18.0\n",
      "Accuracy  36.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.0, 36.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0.5\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 0\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 1, 0]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b59d2939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [0, 1, 0]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0.15\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 0\n",
      "snippets generated File created \n",
      "18.5\n",
      "Accuracy  37.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.5, 37.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0.15\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 0\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 1, 0]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0baa8ba",
   "metadata": {
    "id": "a0baa8ba"
   },
   "source": [
    "# 1.  Argument context modelling task evaluation d =0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea8397",
   "metadata": {},
   "source": [
    "## Stage 1. Context of an argument :  Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46c6448a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "46c6448a",
    "outputId": "6d156157-d4ee-449a-a5e3-79f9b2eba69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [0, 1, 0]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 0\n",
      "snippets generated File created \n",
      "18.5\n",
      "Accuracy  37.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.5, 37.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 0\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 1, 0]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b3622",
   "metadata": {},
   "source": [
    "## Stage 1. Context of an argument : Aspect(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2a952ba",
   "metadata": {
    "id": "f2a952ba",
    "outputId": "f83e6dc9-39b5-4e05-fa65-7877c713bb11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [0, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 50\n",
      "snippets generated File created \n",
      "20.0\n",
      "Accuracy  40.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20.0, 40.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 50\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 0, 1]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91542831",
   "metadata": {},
   "source": [
    "## Stage 1. Context of an argument : Aspect(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "784850b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [0, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 200\n",
      "snippets generated File created \n",
      "20.5\n",
      "Accuracy  41.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20.5, 41.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 200\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 0, 1]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6045c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-54dcdee5dcc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maspects_arguments_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0maspects_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0marguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# argument_context =[1,1,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# argument_context_clusters = ['query',same page','aspect']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_args' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 100\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 0, 1]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd3d6d",
   "metadata": {},
   "source": [
    "## Stage  2. Context of an argument :  Query+  Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2564c5ec",
   "metadata": {
    "id": "2564c5ec",
    "outputId": "7089a512-b9ce-48ab-c68e-6f0e2965440c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 1, 0]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 0\n",
      "snippets generated File created \n",
      "19.5\n",
      "Accuracy  39.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.5, 39.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 0\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [1, 1, 0]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d75cd",
   "metadata": {},
   "source": [
    "## Stage2. Context of an argument : Aspect + Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78fd24b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "78fd24b8",
    "outputId": "34a863ee-7535-479c-aa2b-b9986376409d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 50\n",
      "snippets generated File created \n",
      "21.0\n",
      "Accuracy  42.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21.0, 42.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 50\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [1, 0, 1]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25a4e4",
   "metadata": {},
   "source": [
    "## Stage 2. Context of an argument : Aspect ( 50 ) + Query + same page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3d99ce2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "c3d99ce2",
    "outputId": "09409466-72c3-4430-90b7-e71a9b1ee78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 1, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 50\n",
      "snippets generated File created \n",
      "20.5\n",
      "Accuracy  41.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20.5, 41.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'linear'\n",
    "aspects_arguments_max = 50\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [1, 1, 1]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfa84ff",
   "metadata": {},
   "source": [
    "##  Stage 2. Context of an argument : Aspect(100) + Query + same page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3ab3e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 1, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 100\n",
      "snippets generated File created \n",
      "19.5\n",
      "Accuracy  39.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.5, 39.0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 100\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [1, 1, 1]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "\n",
    "evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a33960",
   "metadata": {
    "id": "55a33960"
   },
   "source": [
    "## Stage 3. Context of an Argument \n",
    "## Evaluation on  number of aspect generated arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f730cd32",
   "metadata": {
    "id": "f730cd32",
    "outputId": "2c2363bd-00dd-4594-abe6-68618c408e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 0\n",
      "snippets generated File created \n",
      "19.5\n",
      "Accuracy  39.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 50\n",
      "snippets generated File created \n",
      "21.0\n",
      "Accuracy  42.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 100\n",
      "WARNING:tensorflow:5 out of the last 54 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C8D781BC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C8D781BC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippets generated File created \n",
      "21.0\n",
      "Accuracy  42.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 125\n",
      "snippets generated File created \n",
      "21.5\n",
      "Accuracy  43.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 150\n",
      "snippets generated File created \n",
      "22.0\n",
      "Accuracy  44.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 175\n",
      "snippets generated File created \n",
      "22.0\n",
      "Accuracy  44.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 200\n",
      "snippets generated File created \n",
      "22.5\n",
      "Accuracy  45.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 225\n",
      "snippets generated File created \n",
      "22.0\n",
      "Accuracy  44.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 250\n",
      "snippets generated File created \n",
      "21.5\n",
      "Accuracy  43.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 275\n",
      "snippets generated File created \n",
      "21.5\n",
      "Accuracy  43.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 300\n",
      "snippets generated File created \n",
      "21.0\n",
      "Accuracy  42.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 350\n",
      "snippets generated File created \n",
      "21.0\n",
      "Accuracy  42.0\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 400\n",
      "snippets generated File created \n",
      "21.0\n",
      "Accuracy  42.0\n"
     ]
    }
   ],
   "source": [
    "d = 0\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "mc_method = 'eigen'\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "count_list =[]\n",
    "accuracy_list =[]\n",
    "\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "aspects_arguments_max_list = [0,50,100,125,150,175,200,225,250,275,300,350,400]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "argument_context =[1,0,1]\n",
    "\n",
    "accuracy_list_aspect = []\n",
    "count_list_aspect =[]\n",
    "\n",
    "\n",
    "for aspects_arguments_max in aspects_arguments_max_list:\n",
    "    count,accuracy =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n",
    "    accuracy_list_aspect.append(accuracy)\n",
    "    count_list_aspect.append(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "023b78e9",
   "metadata": {
    "id": "023b78e9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "evaluation_aspect_detection_test = pd.DataFrame(\n",
    "    {'Number of Arguemts': aspects_arguments_max_list,\n",
    "     'match count': count_list_aspect,\n",
    "     'accuracy (%)': accuracy_list_aspect\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa0e5b3c",
   "metadata": {
    "id": "fa0e5b3c",
    "outputId": "6db51783-c05f-4509-fb59-f362a593d8cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Arguemts</th>\n",
       "      <th>match count</th>\n",
       "      <th>accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>21.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>22.5</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>225</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>21.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>275</td>\n",
       "      <td>21.5</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>350</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Arguemts  match count  accuracy (%)\n",
       "0                    0         19.5          39.0\n",
       "1                   50         21.0          42.0\n",
       "2                  100         21.0          42.0\n",
       "3                  125         21.5          43.0\n",
       "4                  150         22.0          44.0\n",
       "5                  175         22.0          44.0\n",
       "6                  200         22.5          45.0\n",
       "7                  225         22.0          44.0\n",
       "8                  250         21.5          43.0\n",
       "9                  275         21.5          43.0\n",
       "10                 300         21.0          42.0\n",
       "11                 350         21.0          42.0\n",
       "12                 400         21.0          42.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_aspect_detection_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4366a24",
   "metadata": {
    "id": "f4366a24"
   },
   "outputs": [],
   "source": [
    "evaluation_aspect_detection_test.to_csv('data/evaluation_aspect_detection_test2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb70a7",
   "metadata": {},
   "source": [
    "## 1b. Context of an Argument Evaluation on  number of aspect generated arguments on DevSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5de761",
   "metadata": {
    "id": "ec5de761",
    "outputId": "13280db5-3321-47a7-b1f3-ee6188d17361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 0\n",
      "WARNING:tensorflow:5 out of the last 54 calls to <function recreate_function.<locals>.restored_function_body at 0x0000017315252168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function recreate_function.<locals>.restored_function_body at 0x0000017315252168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 55 calls to <function recreate_function.<locals>.restored_function_body at 0x00000173E6B57C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 55 calls to <function recreate_function.<locals>.restored_function_body at 0x00000173E6B57C18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippets generated File created \n",
      "8.5\n",
      "Accuracy  31.48148148148148\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 50\n",
      "snippets generated File created \n",
      "9.5\n",
      "Accuracy  35.18518518518518\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 100\n",
      "snippets generated File created \n",
      "10.5\n",
      "Accuracy  38.888888888888886\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 150\n",
      "snippets generated File created \n",
      "12.0\n",
      "Accuracy  44.44444444444444\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 200\n",
      "snippets generated File created \n",
      "12.5\n",
      "Accuracy  46.2962962962963\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 250\n",
      "snippets generated File created \n",
      "11.5\n",
      "Accuracy  42.592592592592595\n",
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method discourse_claim_markers d: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 300\n",
      "snippets generated File created \n",
      "11.5\n",
      "Accuracy  42.592592592592595\n"
     ]
    }
   ],
   "source": [
    "d = 0\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "mc_method = 'eigen'\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "count_list =[]\n",
    "accuracy_list =[]\n",
    "\n",
    "aspects_weights = [0, 0]\n",
    "arguments = dev_args\n",
    "# aspects_arguments_max_list = [0,50,100,150,200,250,300]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "argument_context =[1,0,1]\n",
    "\n",
    "accuracy_list_aspect = []\n",
    "count_list_aspect =[]\n",
    "\n",
    "\n",
    "for aspects_arguments_max in aspects_arguments_max_list:\n",
    "    accuracy, count =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n",
    "    accuracy_list_aspect.append(accuracy)\n",
    "    count_list_aspect.append(count)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8119640d",
   "metadata": {
    "id": "8119640d"
   },
   "source": [
    "# 2.  Argumentativeness Computation task evaluation d =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_list_args_method = []\n",
    "count_list_args_method = []\n",
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 1\n",
    "mc_method = 'eigen'\n",
    "\n",
    "aspects_arguments_max = 0\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0, 0, 0]\n",
    "#argumentative_score_method = argumentative_score_methods[0]\n",
    "for argumentative_score_method in argumentative_score_methods:\n",
    "    count, accuracy =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n",
    "    accuracy_list_args_method.append(accuracy)\n",
    "    count_list_args_method.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae76c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "evaluation_argumentation_methods_test = pd.DataFrame(\n",
    "    {'Argumentataion-score-methods': argumentative_score_methods,\n",
    "     'match count': count_list_args_method,\n",
    "     'accuracy (%)': accuracy_list_args_method\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "216cfb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argumentataion-score-methods</th>\n",
       "      <th>accuracy (%)</th>\n",
       "      <th>match count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discourse_claim_markers</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argument_score</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claim_score</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hybrid_score</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argumentataion-score-methods  accuracy (%)  match count\n",
       "0      discourse_claim_markers          29.0         14.5\n",
       "1               argument_score          38.0         19.0\n",
       "2                  claim_score          29.0         14.5\n",
       "3                 hybrid_score          40.0         20.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_argumentation_methods_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f4ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_argumentation_methods_test.to_csv('data/evaluation_argumentation_methods_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe7ef6d",
   "metadata": {},
   "source": [
    "## 2.  Argumentativeness Computation task evaluation d =1\n",
    "## Argumentative Computation Method (Hybrid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182759c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list_args_method = []\n",
    "count_list_args_method = []\n",
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = [ 'hybrid_score']\n",
    "d = 1\n",
    "mc_method = 'linear'\n",
    "aspects_arguments_max = 0\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0,1, 0]\n",
    "\n",
    "for argumentative_score_method in argumentative_score_methods:\n",
    "    count, accuracy =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n",
    "    accuracy_list_args_method.append(accuracy)\n",
    "    count_list_args_method.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "GmUFjBCT--xt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "GmUFjBCT--xt",
    "outputId": "070f360e-e584-4bb1-ce57-bdea3c3c1b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [1, 0, 1]\n",
      "Markov Chain Method linear Argumentative Score Method hybrid_score d: 0.5\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C5888A0288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C5888A0288> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 200\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C58888EC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C58888EC18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippets generated File created \n",
      "20.0\n",
      "Accuracy  40.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_args_method = []\n",
    "count_list_args_method = []\n",
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0.5\n",
    "mc_method = 'linear'\n",
    "aspects_arguments_max = 200\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args\n",
    "argumentative_score_method = argumentative_score_methods[3]\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [1,0,1]\n",
    "count, accuracy =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94ed06",
   "metadata": {},
   "source": [
    "# 3. Snipppet Generation Topic-Wise Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1b9a6",
   "metadata": {},
   "source": [
    "##  Argument context  + Argumentaitveness method (Hybrid_Score) (d = 0.5) Topic:  Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74f656ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context_array [0, 0, 1]\n",
      "Markov Chain Method eigen Argumentative Score Method hybrid_score d: 0.5\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C570A59948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 15 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C570A59948> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspects_weights: [0, 0] aspects_arguments_max 5\n",
      "WARNING:tensorflow:7 out of the last 16 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C570A48A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 16 calls to <function recreate_function.<locals>.restored_function_body at 0x000001C570A48A68> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snippets generated File created \n",
      "4.5\n",
      "Accuracy  50.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_args_method = []\n",
    "count_list_args_method = []\n",
    "\n",
    "# methodSet = ['power','eigen','linear','krylov']\n",
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "d = 0.5\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 5\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args[0:9]\n",
    "argumentative_score_method = argumentative_score_methods[3]\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [0,0,1]\n",
    "count, accuracy =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e99e4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d_count =  []\n",
    "d_accuracy = []\n",
    "d_values = np.linspace(0,1,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40911cad",
   "metadata": {},
   "source": [
    "###   Topic wise Evaluation Changing the value of d  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "argumentative_score_methods = ['discourse_claim_markers', 'argument_score', 'claim_score', 'hybrid_score']\n",
    "mc_method = 'eigen'\n",
    "aspects_arguments_max = 200\n",
    "aspects_weights = [0, 0]\n",
    "arguments = test_args[0:9]\n",
    "argumentative_score_method = argumentative_score_methods[0]\n",
    "# argument_context =[1,1,1]\n",
    "# argument_context_clusters = ['query',same page','aspect']\n",
    "argument_context = [1,0,1]\n",
    "\n",
    "\n",
    "for d in d_values:\n",
    "    count, accuracy =evaluation(arguments, d, mc_method, aspects_arguments_max, aspects_weights,\n",
    "               argument_context, argumentative_score_method)\n",
    "    d_accuracy.append(accuracy)\n",
    "    d_count.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb429688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.6, 0.8, 1. ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "18431147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55.55555555555556,\n",
       " 55.55555555555556,\n",
       " 50.0,\n",
       " 50.0,\n",
       " 44.44444444444444,\n",
       " 38.888888888888886,\n",
       " 27.77777777777778]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SnippetsEvaluation_topic_split_google_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0711fe0e17f44a809ad502f1bea622f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e00ca8181b444ff98be59df480be85b8",
       "IPY_MODEL_dd24551affda44498b056d42d390516a"
      ],
      "layout": "IPY_MODEL_1bb1824d78c040989241849b6bf0e6dc"
     }
    },
    "0a338f9975964fa5b8c6108b78aa6b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4f2272ab4c949188522c549bac43fbe",
      "max": 498679241,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6d8f96dc9aa45368834255fc69244f5",
      "value": 498679241
     }
    },
    "136b2c7dc3a244ccb24ed6ba7d6cf4a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6acf8444c00d43418f82fde5131d65aa",
       "IPY_MODEL_15aea6429edb418882bb4136583b0797"
      ],
      "layout": "IPY_MODEL_6499773ba805468d9234d486fce0ffd3"
     }
    },
    "15aea6429edb418882bb4136583b0797": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76144edcf1a644fc85705f5f3277e98e",
      "placeholder": "​",
      "style": "IPY_MODEL_ce53a2453da545ca98590447a3bea7e7",
      "value": " 798k/798k [00:00&lt;00:00, 979kB/s]"
     }
    },
    "1bb1824d78c040989241849b6bf0e6dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "201d97219c2f41f3bacfc87560fdda1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2573a61c0701450cae8ccbf220213579": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "276b2f3c8efa49bc8c99911db544b858": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a694f1aba2b24f01a5d3cdd2c1c6fda2",
      "placeholder": "​",
      "style": "IPY_MODEL_53395e59bd55413f9729192aeb20211f",
      "value": " 499M/499M [00:12&lt;00:00, 39.4MB/s]"
     }
    },
    "300a9ad1919745e0bb064c0a24872578": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3634ec9092dc4f9c91fc73557deebb1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b237af0ac868461aa7b14783f0d666e5",
      "placeholder": "​",
      "style": "IPY_MODEL_4bf04b7b31ff450484d27032fd54d9aa",
      "value": " 255/255 [00:00&lt;00:00, 2.72kB/s]"
     }
    },
    "427f5fae2c01431184e49170cb5fbb0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "497a33d67fd24cbbb10550b8f177a3c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77f6327fcfae4340ba47a992e812cc4d",
      "max": 790,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de5844b309444039a75610c992b269d1",
      "value": 790
     }
    },
    "4bf04b7b31ff450484d27032fd54d9aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51112895f0984853aa72e2c7d7166b8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "53395e59bd55413f9729192aeb20211f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54431eb739304492b034bc55fe0303d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6499773ba805468d9234d486fce0ffd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6862247d45ae41148eab375db99d60ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68c53fac07764e6e8ddeb0c3a5522c9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6acf8444c00d43418f82fde5131d65aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_758f91563cc24542a3bb7c241371ce6c",
      "max": 798293,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c747c98d8ed4f7991e251fc4404ea2d",
      "value": 798293
     }
    },
    "6ba2714e8a4b4926a29745879d9202f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db8725d6073448e92728fb7ec4b7e51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c33f6f28355146f09a3c0ff5c2edbc22",
      "max": 456356,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75335056443147d2bfa3c6840fe1183f",
      "value": 456356
     }
    },
    "7296c218ab304f95beba77671030f7cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75335056443147d2bfa3c6840fe1183f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "758f91563cc24542a3bb7c241371ce6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76144edcf1a644fc85705f5f3277e98e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77f6327fcfae4340ba47a992e812cc4d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a455b71258c40f5abd5894020dfe3d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c747c98d8ed4f7991e251fc4404ea2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90e85715d07d480c9d327b722fe440b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a694f1aba2b24f01a5d3cdd2c1c6fda2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b237af0ac868461aa7b14783f0d666e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be7396737a8b4cdbacd83ffd75b4e277": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a338f9975964fa5b8c6108b78aa6b30",
       "IPY_MODEL_276b2f3c8efa49bc8c99911db544b858"
      ],
      "layout": "IPY_MODEL_90e85715d07d480c9d327b722fe440b4"
     }
    },
    "c33f6f28355146f09a3c0ff5c2edbc22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3409288f983432387160b54cb16704b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4f2272ab4c949188522c549bac43fbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6d8f96dc9aa45368834255fc69244f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ce1f0490532048969a17b5cab3018667": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6db8725d6073448e92728fb7ec4b7e51",
       "IPY_MODEL_e78d243062524f709d5cfce00e705445"
      ],
      "layout": "IPY_MODEL_68c53fac07764e6e8ddeb0c3a5522c9d"
     }
    },
    "ce53a2453da545ca98590447a3bea7e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfa62bd3b00f4da7a27810819d104337": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6862247d45ae41148eab375db99d60ec",
      "max": 255,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e5331efd11054c73acc73df6c8e9a10d",
      "value": 255
     }
    },
    "dd24551affda44498b056d42d390516a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54431eb739304492b034bc55fe0303d0",
      "placeholder": "​",
      "style": "IPY_MODEL_7a455b71258c40f5abd5894020dfe3d8",
      "value": " 239/239 [00:00&lt;00:00, 330B/s]"
     }
    },
    "de5844b309444039a75610c992b269d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e00ca8181b444ff98be59df480be85b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_427f5fae2c01431184e49170cb5fbb0c",
      "max": 239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51112895f0984853aa72e2c7d7166b8c",
      "value": 239
     }
    },
    "e5331efd11054c73acc73df6c8e9a10d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e78d243062524f709d5cfce00e705445": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ba2714e8a4b4926a29745879d9202f3",
      "placeholder": "​",
      "style": "IPY_MODEL_300a9ad1919745e0bb064c0a24872578",
      "value": " 456k/456k [00:02&lt;00:00, 224kB/s]"
     }
    },
    "e88a24f225bc4ccba56a9dbcabb43bde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfa62bd3b00f4da7a27810819d104337",
       "IPY_MODEL_3634ec9092dc4f9c91fc73557deebb1f"
      ],
      "layout": "IPY_MODEL_201d97219c2f41f3bacfc87560fdda1b"
     }
    },
    "f5d207e85f5640e3858419a38837290e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2573a61c0701450cae8ccbf220213579",
      "placeholder": "​",
      "style": "IPY_MODEL_7296c218ab304f95beba77671030f7cb",
      "value": " 790/790 [00:03&lt;00:00, 227B/s]"
     }
    },
    "fabfbb94efd0487d9d4007731efb651b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_497a33d67fd24cbbb10550b8f177a3c0",
       "IPY_MODEL_f5d207e85f5640e3858419a38837290e"
      ],
      "layout": "IPY_MODEL_c3409288f983432387160b54cb16704b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
